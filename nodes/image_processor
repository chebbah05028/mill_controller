#!/usr/bin/env python

"""
This script contains a ROS node that will receive Image messages over the topic 'raw_image', convert them into OpenCV images, perform computer vision tasks, currently placeholder, convert them back into Image messages and publish them on the topic 'processed_image'.
"""

import rospkg
import rospy
import cv2
import numpy as np
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError


# Use this publisher to send the output
pub = rospy.Publisher('processed_image',Image,queue_size=1)

# Create a translator object to convert images
converter = CvBridge()

# Set threshold for color processing
threshold = 500

# Initialize global variables for homography, width, and height to None
_h = _width = _height = None

# Constants
MAX_FEATURES = 500
GOOD_MATCH_PERCENT = 0.67


def callback(input):
    # The callback accepts an Image message, performs visual processing and masking on it, and publishes the result. Exact processing is placeholder. I'm going to start by assuming the presence of material at every location in the frame except where darker colors are present. Darker pixels will then be changed to black, non-dark pixels will be made white.

    # Translate Image message into a cv2 image assuming bgr8 encoding. The image will revert to a more general CV encoding, like 8UC3.
    cv_image = converter.imgmsg_to_cv2(input,"bgr8")

    # Make a copy, as the original image will not be editable after conversion
    cv_image = cv_image.copy()

    # Apply a homography to warp the new image to match the reference
    aligned_cv_image = cv2.warpPerspective(cv_image, _h, (_width, _height))

    # Perform visual processing on the image to extract relevant data.
    # Extract a tuple containing the number of (rows, columns, channels).
    (rows,cols,chans)  = aligned_cv_image.shape

    # Cycle through each row
    for row in range(rows):
        # Cycle through each column
        for col in range(cols):
            total = 0
            # Cycle through each channel
            for chan in range(chans):
                # Sum the intensity of the channels
                total += aligned_cv_image.item(row,col,chan)

            # Cycle through each channel
            for chan in range(chans):
                # If the total intensity is less than the threshold
                if (total < threshold):
                    # Set color to black
                    aligned_cv_image.itemset((row,col,chan),0)
                else:
                    # Set the color to white
                    aligned_cv_image.itemset((row,col,chan),255)


    # Translate cv2 image back to an Image message using existing encoding. This will be a generic encoding like 8UC3.
    msg = converter.cv2_to_imgmsg(aligned_cv_image,"passthrough")

    # Assert encoding. CV generally uses bgr8.
    msg.encoding = "bgr8"

    # Publish image message
    pub.publish(msg)


def setup_callback(input):
    # Calculate the homography between the new image and the reference
    # Save homography, reference width and height into global variable

    # Declare the use of global _h
    global _h, _width, _height

    # Convert new image using bgr8 encoding(?).
    cam_img = converter.imgmsg_to_cv2(input,"bgr8")
    # Read in reference image
    rospack = rospkg.RosPack()
    path = rospack.get_path('mill_controller') + '/images/tags_r.jpg'
    ref_img = cv2.imread(path, cv2.IMREAD_COLOR)


    # Convert images to grayscale
    cam_img_gray = cv2.cvtColor(cam_img, cv2.COLOR_BGR2GRAY)
    ref_img_gray = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)

    # Detect ORB features and compute descriptors.
    orb = cv2.ORB_create(MAX_FEATURES)
    keypoints1, descriptors1 = orb.detectAndCompute(cam_img_gray, None)
    keypoints2, descriptors2 = orb.detectAndCompute(ref_img_gray, None)

    # Match features
    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)
    matches = matcher.match(descriptors1, descriptors2, None)

    # Rank and Cull matches
    matches.sort(key=lambda x: x.distance, reverse=False)
    numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)
    matches = matches[:numGoodMatches]

    # Produce lists of match coordinates
    points1 = np.zeros((len(matches), 2), dtype=np.float32)
    points2 = np.zeros((len(matches), 2), dtype=np.float32)

    for i, match in enumerate(matches):
        points1[i, :] = keypoints1[match.queryIdx].pt
        points2[i, :] = keypoints2[match.trainIdx].pt

    # Find homography using RANSAC algorithm
    _h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)
    # Set globals width, height. Channels will be discarded.
    _height, _width, channels = ref_img.shape





def main():
    # Initialize ROS node
    rospy.init_node("image_processor_node")

    # Initialize a subscriber to the camera driver. Hang on to the object for this one.
    sub = rospy.Subscriber('usb_cam/image_raw',Image,setup_callback)

    # Wait for setup_callback to activate and set _h
    while (np.any(_h == None)) and (not rospy.is_shutdown()):

        rospy.sleep(1)

    #Target logic: Ensure that only one callback can occur at a time, and no extras will be processed
    while(not calibrated):
        blocking = True
        Call a SINGLE callback # May be able to do this by limiting subscriber queue to 1 message. Other methods seem more advanced and/or unavailable.
        while(blocking):
            wait
            #Blocking is cleared in callback
        #Calibrated is set in callback

    # Unsubscribe and destroy subscriber
    sub.unregister()
    del sub

    # Initialize Main Subscriber
    rospy.Subscriber('raw_image',Image,callback)

    # Spin until shut down
    rospy.spin()





if __name__ == '__main__':
    main()
